{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![TinyLogger Logo](artifacts/littlelogger-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. The Problem: Losing Track of Experiments\n",
    "\n",
    "We've all been here. You're in a notebook, trying to find the best hyperparameters for a model. You try a few combinations, and soon your notebook is a mess and you've lost track of which run gave the best score.\n",
    "\n",
    "```python\n",
    "# Which one was best again?\n",
    "# run 1: 0.82 f1\n",
    "# run 2: 0.81 f1\n",
    "# run 3: 0.83 f1 (I think this was max_depth=5? Or 7?)\n",
    "```\n",
    "\n",
    "**`LittleLogger` solves this.** It's a zero-setup decorator that automatically logs your function's inputs (params) and outputs (metrics) to a simple file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Installation & Setup\n",
    "\n",
    "First, let's install the logger. If you're running this from inside the cloned project repository, you can install it in editable mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the package from PyPI\n",
    "# %pip install littlelogger\n",
    "\n",
    "# We also need scikit-learn for this demo\n",
    "# %pip install scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import littlelogger\n",
    "from littlelogger import log_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.0.0'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "littlelogger.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed old log file: experiment_log.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Define our log file path\n",
    "LOG_FILE = \"experiment_log.jsonl\"\n",
    "\n",
    "# Let's delete any old logs to start fresh for this demo\n",
    "if os.path.exists(LOG_FILE):\n",
    "    os.remove(LOG_FILE)\n",
    "    print(f\"Removed old log file: {LOG_FILE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create a Reusable Dataset\n",
    "\n",
    "We'll create a simple, reusable dataset for our demo. This way, we're not regenerating data inside our training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created dataset: X_train shape (800, 20), X_test shape (200, 20)\n"
     ]
    }
   ],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=20,\n",
    "    n_informative=10,\n",
    "    n_redundant=5,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Created dataset: X_train shape {X_train.shape}, X_test shape {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Decorate Your Training Functions\n",
    "\n",
    "We'll create two *different* model training functions. All we have to do is add `@log_run()` to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_run(log_file=LOG_FILE)\n",
    "def train_random_forest(n_estimators, max_depth, min_samples_leaf=1):\n",
    "    \"\"\"Train a RandomForestClassifier.\"\"\"\n",
    "    print(f\"Training RandomForest with n_estimators={n_estimators}, max_depth={max_depth}...\")\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": round(accuracy, 4), \"f1_score\": round(f1, 4)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_run(log_file=LOG_FILE)\n",
    "def train_svc(C, kernel, degree=3):\n",
    "    \"\"\"Train an SVC (Support Vector Classifier).\"\"\"\n",
    "    print(f\"Training SVC with C={C}, kernel={kernel}...\")\n",
    "\n",
    "    # SVCs are sensitive to feature scale, so we use a Pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', SVC(\n",
    "            C=C,\n",
    "            kernel=kernel,\n",
    "            degree=degree,\n",
    "            random_state=42\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    return {\"accuracy\": round(accuracy, 4), \"f1_score\": round(f1, 4)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Run the Experiments\n",
    "\n",
    "Now we can run *both* sets of experiments, and all the results will go into the *same* log file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting RandomForest Sweep ---\n",
      "\n",
      "--- Starting RF Run 1 ---\n",
      "Training RandomForest with n_estimators=50, max_depth=5...\n",
      "\n",
      "--- Starting RF Run 2 ---\n",
      "Training RandomForest with n_estimators=100, max_depth=10...\n",
      "\n",
      "--- Starting RF Run 3 ---\n",
      "Training RandomForest with n_estimators=200, max_depth=None...\n",
      "\n",
      "--- All Experiments Finished ---\n"
     ]
    }
   ],
   "source": [
    "# RandomForest Sweep\n",
    "rf_param_grid = [\n",
    "    {'n_estimators': 50, 'max_depth': 5},\n",
    "    {'n_estimators': 100, 'max_depth': 10},\n",
    "    {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 2},\n",
    "]\n",
    "\n",
    "print(\"--- Starting RandomForest Sweep ---\")\n",
    "\n",
    "for i, params in enumerate(rf_param_grid):\n",
    "    print(f\"\\n--- Starting RF Run {i + 1} ---\")\n",
    "    train_random_forest(**params)\n",
    "\n",
    "print(\"\\n--- All Experiments Finished ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting SVC Sweep ---\n",
      "\n",
      "--- Starting SVC Run 1 ---\n",
      "Training SVC with C=1.0, kernel=rbf...\n",
      "\n",
      "--- Starting SVC Run 2 ---\n",
      "Training SVC with C=1.0, kernel=linear...\n",
      "\n",
      "--- Starting SVC Run 3 ---\n",
      "Training SVC with C=0.5, kernel=rbf...\n",
      "\n",
      "--- All Experiments Finished ---\n"
     ]
    }
   ],
   "source": [
    "# --- SVC Sweep ---\n",
    "svc_param_grid = [\n",
    "    {'C': 1.0, 'kernel': 'rbf'},\n",
    "    {'C': 1.0, 'kernel': 'linear'},\n",
    "    {'C': 0.5, 'kernel': 'rbf'},\n",
    "]\n",
    "\n",
    "print(\"\\n--- Starting SVC Sweep ---\")\n",
    "\n",
    "for i, params in enumerate(svc_param_grid):\n",
    "    print(f\"\\n--- Starting SVC Run {i + 1} ---\")\n",
    "    train_svc(**params)\n",
    "\n",
    "print(\"\\n--- All Experiments Finished ---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. The Payoff: Analyzing Your Combined Results\n",
    "\n",
    "This is the best part. We read the *single* log file into pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>function_name</th>\n",
       "      <th>runtime_seconds</th>\n",
       "      <th>params</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-02 07:25:38+00:00</td>\n",
       "      <td>train_random_forest</td>\n",
       "      <td>0.457470</td>\n",
       "      <td>{'n_estimators': 50, 'max_depth': 5, 'min_samp...</td>\n",
       "      <td>{'accuracy': 0.88, 'f1_score': 0.8799}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02 07:25:38+00:00</td>\n",
       "      <td>train_random_forest</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>{'n_estimators': 100, 'max_depth': 10, 'min_sa...</td>\n",
       "      <td>{'accuracy': 0.915, 'f1_score': 0.915}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_random_forest</td>\n",
       "      <td>0.483620</td>\n",
       "      <td>{'n_estimators': 200, 'max_depth': None, 'min_...</td>\n",
       "      <td>{'accuracy': 0.92, 'f1_score': 0.92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'rbf', 'degree': 3}</td>\n",
       "      <td>{'accuracy': 0.9450000000000001, 'f1_score': 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>{'C': 1.0, 'kernel': 'linear', 'degree': 3}</td>\n",
       "      <td>{'accuracy': 0.805, 'f1_score': 0.804900000000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>{'C': 0.5, 'kernel': 'rbf', 'degree': 3}</td>\n",
       "      <td>{'accuracy': 0.93, 'f1_score': 0.93}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp        function_name  runtime_seconds  \\\n",
       "0 2025-11-02 07:25:38+00:00  train_random_forest         0.457470   \n",
       "1 2025-11-02 07:25:38+00:00  train_random_forest         0.273800   \n",
       "2 2025-11-02 07:25:39+00:00  train_random_forest         0.483620   \n",
       "3 2025-11-02 07:25:39+00:00            train_svc         0.071125   \n",
       "4 2025-11-02 07:25:39+00:00            train_svc         0.030865   \n",
       "5 2025-11-02 07:25:39+00:00            train_svc         0.025628   \n",
       "\n",
       "                                              params  \\\n",
       "0  {'n_estimators': 50, 'max_depth': 5, 'min_samp...   \n",
       "1  {'n_estimators': 100, 'max_depth': 10, 'min_sa...   \n",
       "2  {'n_estimators': 200, 'max_depth': None, 'min_...   \n",
       "3           {'C': 1.0, 'kernel': 'rbf', 'degree': 3}   \n",
       "4        {'C': 1.0, 'kernel': 'linear', 'degree': 3}   \n",
       "5           {'C': 0.5, 'kernel': 'rbf', 'degree': 3}   \n",
       "\n",
       "                                             metrics  \n",
       "0             {'accuracy': 0.88, 'f1_score': 0.8799}  \n",
       "1             {'accuracy': 0.915, 'f1_score': 0.915}  \n",
       "2               {'accuracy': 0.92, 'f1_score': 0.92}  \n",
       "3  {'accuracy': 0.9450000000000001, 'f1_score': 0...  \n",
       "4  {'accuracy': 0.805, 'f1_score': 0.804900000000...  \n",
       "5               {'accuracy': 0.93, 'f1_score': 0.93}  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is the magic line!\n",
    "df_raw = pd.read_json(LOG_FILE, lines=True)\n",
    "\n",
    "df_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, when we use `json_normalize`, pandas will *automatically* create columns for all parameters (`n_estimators`, `C`, `kernel`, etc.) and fill in `NaN` for the runs where that parameter didn't apply. \n",
    "\n",
    "This makes comparing different model types incredibly easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>function_name</th>\n",
       "      <th>runtime_seconds</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>metric_accuracy</th>\n",
       "      <th>metric_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-02 07:25:38+00:00</td>\n",
       "      <td>train_random_forest</td>\n",
       "      <td>0.457470</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-02 07:25:38+00:00</td>\n",
       "      <td>train_random_forest</td>\n",
       "      <td>0.273800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.9150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_random_forest</td>\n",
       "      <td>0.483620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.9200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.9450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.030865</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.805</td>\n",
       "      <td>0.8049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.025628</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.9300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp        function_name  runtime_seconds  param_C  \\\n",
       "0 2025-11-02 07:25:38+00:00  train_random_forest         0.457470      NaN   \n",
       "1 2025-11-02 07:25:38+00:00  train_random_forest         0.273800      NaN   \n",
       "2 2025-11-02 07:25:39+00:00  train_random_forest         0.483620      NaN   \n",
       "3 2025-11-02 07:25:39+00:00            train_svc         0.071125      1.0   \n",
       "4 2025-11-02 07:25:39+00:00            train_svc         0.030865      1.0   \n",
       "5 2025-11-02 07:25:39+00:00            train_svc         0.025628      0.5   \n",
       "\n",
       "   param_degree param_kernel  param_max_depth  param_min_samples_leaf  \\\n",
       "0           NaN          NaN              5.0                     1.0   \n",
       "1           NaN          NaN             10.0                     1.0   \n",
       "2           NaN          NaN              NaN                     2.0   \n",
       "3           3.0          rbf              NaN                     NaN   \n",
       "4           3.0       linear              NaN                     NaN   \n",
       "5           3.0          rbf              NaN                     NaN   \n",
       "\n",
       "   param_n_estimators  metric_accuracy  metric_f1_score  \n",
       "0                50.0            0.880           0.8799  \n",
       "1               100.0            0.915           0.9150  \n",
       "2               200.0            0.920           0.9200  \n",
       "3                 NaN            0.945           0.9450  \n",
       "4                 NaN            0.805           0.8049  \n",
       "5                 NaN            0.930           0.9300  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use json_normalize and then add_prefix\n",
    "df_params = pd.json_normalize(df_raw['params']).add_prefix('param_')\n",
    "df_metrics = pd.json_normalize(df_raw['metrics']).add_prefix('metric_')\n",
    "\n",
    "# Get the other columns we want\n",
    "df_main = df_raw[['timestamp', 'function_name', 'runtime_seconds']]\n",
    "\n",
    "# Join them all together into one clean DataFrame\n",
    "df = pd.concat([df_main, df_params, df_metrics], axis=1)\n",
    "\n",
    "# Re-order columns to group params and metrics for clarity\n",
    "all_cols = (list(df_main.columns) +\n",
    "           sorted([c for c in df.columns if c.startswith('param_')]) +\n",
    "           sorted([c for c in df.columns if c.startswith('metric_')]))\n",
    "\n",
    "df[all_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, finding your *overall* best run is trivial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>function_name</th>\n",
       "      <th>runtime_seconds</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_min_samples_leaf</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_degree</th>\n",
       "      <th>metric_accuracy</th>\n",
       "      <th>metric_f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-02 07:25:39+00:00</td>\n",
       "      <td>train_svc</td>\n",
       "      <td>0.071125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rbf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp function_name  runtime_seconds  \\\n",
       "3 2025-11-02 07:25:39+00:00     train_svc         0.071125   \n",
       "\n",
       "   param_n_estimators  param_max_depth  param_min_samples_leaf  param_C  \\\n",
       "3                 NaN              NaN                     NaN      1.0   \n",
       "\n",
       "  param_kernel  param_degree  metric_accuracy  metric_f1_score  \n",
       "3          rbf           3.0            0.945            0.945  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by our key metric to find the best-performing run\n",
    "df_sorted = df.sort_values(by=\"metric_f1_score\", ascending=False)\n",
    "\n",
    "df_sorted.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Feature: Graceful Error Handling\n",
    "\n",
    "A key feature of `littlelogger` is that it **will never crash your script.**\n",
    "\n",
    "If you return something that can't be saved to JSON, it will simply print a warning and continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running a function that will fail to log...\n",
      "\n",
      "Script continued successfully!\n",
      "We still got our return value: {'model_object': <object object at 0x000002C268EA6090>}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayye\\AppData\\Local\\Temp\\ipykernel_28260\\1276344252.py:9: UserWarning: [LittleLogger Warning] Failed to serialize log entry. Ensure all arguments and return values are JSON-serializable. Original error: Object of type object is not JSON serializable\n",
      "  result = bad_function()\n"
     ]
    }
   ],
   "source": [
    "@log_run(log_file=LOG_FILE)\n",
    "def bad_function():\n",
    "    # We return `object()`, which is not JSON-serializable\n",
    "    return {\"model_object\": object()}\n",
    "\n",
    "print(\"\\nRunning a function that will fail to log...\")\n",
    "\n",
    "# Note: This will print a UserWarning, but NOT crash!\n",
    "result = bad_function()\n",
    "\n",
    "print(\"\\nScript continued successfully!\")\n",
    "print(f\"We still got our return value: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we check the log file, we can see that only the 6 successful runs are in it. The 7th, failed run was skipped, and our script was unharmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total runs logged: 6\n"
     ]
    }
   ],
   "source": [
    "df_final = pd.read_json(LOG_FILE, lines=True)\n",
    "print(f\"Total runs logged: {len(df_final)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
