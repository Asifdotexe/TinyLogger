{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29e23a3",
   "metadata": {},
   "source": [
    "# Demo: Using `littlelogger` with Parallel Tools\n",
    "\n",
    "`GridSearchCV` and other parallel tools use `joblib` to run tasks on multiple CPU cores at once. This creates a \"race condition\" where multiple processes try to write to the same log file, causing corruption.\n",
    "\n",
    "`littlelogger` solves this by adding the unique **Process ID (PID)** to the log file. This guarantees that each parallel worker writes to its *own* safe file.\n",
    "\n",
    "This notebook demonstrates this feature using `joblib` directly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a85120b",
   "metadata": {},
   "source": [
    "### 1. Setup\n",
    "\n",
    "First, we import our tools and define our decorated function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77d87a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning up old logs...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# Import joblib for parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Import our logger\n",
    "from littlelogger import log_run\n",
    "\n",
    "# Define a base log file name\n",
    "LOG_FILE = \"parallel_run.jsonl\"\n",
    "\n",
    "# --- Clean up old log files for this demo ---\n",
    "print(\"Cleaning up old logs...\")\n",
    "for f in glob.glob(f\"{LOG_FILE}.*\"):\n",
    "    os.remove(f)\n",
    "    print(f\"Removed {f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36a1b43",
   "metadata": {},
   "source": [
    "### 2. Define the Decorated Function\n",
    "\n",
    "We decorate our `train_model` function just like before. We'll add a `time.sleep(1)` to simulate real work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2992adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@log_run(log_file=LOG_FILE)\n",
    "def train_model(learning_rate, n_estimators):\n",
    "    \"\"\"A mock training function that sleeps for 1 sec.\"\"\"\n",
    "    print(f\"  Running model with lr={learning_rate}, n_estimators={n_estimators}...\")\n",
    "\n",
    "    # Simulate 1 second of work\n",
    "    time.sleep(1)\n",
    "\n",
    "    # Calculate some mock scores\n",
    "    f1 = 0.8 + (learning_rate * 0.1) - (n_estimators * 0.0001)\n",
    "\n",
    "    print(f\"  Finished model with lr={learning_rate}. F1 = {f1:.4f}\")\n",
    "    return {\"f1_score\": round(f1, 4)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377bbeb0",
   "metadata": {},
   "source": [
    "### 3. Define the Parameter Grid\n",
    "\n",
    "This is the same list of parameters you would pass to `GridSearchCV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a04ff3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created a grid of 6 experiments.\n"
     ]
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {'learning_rate': 0.1, 'n_estimators': 100},\n",
    "    {'learning_rate': 0.1, 'n_estimators': 200},\n",
    "    {'learning_rate': 0.05, 'n_estimators': 100},\n",
    "    {'learning_rate': 0.05, 'n_estimators': 200},\n",
    "    {'learning_rate': 0.01, 'n_estimators': 300},\n",
    "    {'learning_rate': 0.01, 'n_estimators': 500},\n",
    "]\n",
    "\n",
    "print(f\"Created a grid of {len(param_grid)} experiments.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7eabe3",
   "metadata": {},
   "source": [
    "### 4. Run in Parallel!\n",
    "\n",
    "We'll use `joblib` to run all 6 experiments in parallel. `n_jobs=-1` tells it to use all available CPU cores.\n",
    "\n",
    "(If the 6 jobs finish in ~1 second instead of 6 seconds, you know it ran in parallel!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19c37c02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting parallel run... ---\n",
      "\n",
      "--- Parallel run finished in 4.28 seconds --- \n"
     ]
    }
   ],
   "source": [
    "print(\"--- Starting parallel run... ---\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "Parallel(n_jobs=-1)(\n",
    "    delayed(train_model)(**params) for params in param_grid\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"\\n--- Parallel run finished in {end_time - start_time:.2f} seconds --- \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef19260b",
   "metadata": {},
   "source": [
    "### 5. See the Result: Multiple Log Files\n",
    "\n",
    "Now, look in your directory. `littlelogger` has safely created a separate file for each worker process. This is **proof** that no data was corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4785322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 log files:\n",
      "parallel_run.jsonl.14620\n",
      "parallel_run.jsonl.15996\n",
      "parallel_run.jsonl.2016\n",
      "parallel_run.jsonl.23292\n",
      "parallel_run.jsonl.4532\n",
      "parallel_run.jsonl.4772\n"
     ]
    }
   ],
   "source": [
    "log_files = glob.glob(f\"{LOG_FILE}.*\")\n",
    "\n",
    "print(f\"Found {len(log_files)} log files:\")\n",
    "for f in log_files:\n",
    "    print(f) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6177f6",
   "metadata": {},
   "source": [
    "### 6. The Payoff: Combine and Analyze\n",
    "\n",
    "Here is the simple 3-line pattern to combine all these files into one master `pandas` DataFrame for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a27dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined 6 log files into a single DataFrame with 6 runs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>function_name</th>\n",
       "      <th>runtime_seconds</th>\n",
       "      <th>params</th>\n",
       "      <th>metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-16 16:47:49+00:00</td>\n",
       "      <td>train_model</td>\n",
       "      <td>1.000443</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 200}</td>\n",
       "      <td>{'f1_score': 0.785}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-16 16:47:49+00:00</td>\n",
       "      <td>train_model</td>\n",
       "      <td>1.000705</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 500}</td>\n",
       "      <td>{'f1_score': 0.751}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-16 16:47:49+00:00</td>\n",
       "      <td>train_model</td>\n",
       "      <td>1.000741</td>\n",
       "      <td>{'learning_rate': 0.01, 'n_estimators': 300}</td>\n",
       "      <td>{'f1_score': 0.771}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-16 16:47:49+00:00</td>\n",
       "      <td>train_model</td>\n",
       "      <td>1.001190</td>\n",
       "      <td>{'learning_rate': 0.1, 'n_estimators': 200}</td>\n",
       "      <td>{'f1_score': 0.79}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-16 16:47:49+00:00</td>\n",
       "      <td>train_model</td>\n",
       "      <td>1.000646</td>\n",
       "      <td>{'learning_rate': 0.05, 'n_estimators': 100}</td>\n",
       "      <td>{'f1_score': 0.795}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  timestamp function_name  runtime_seconds  \\\n",
       "0 2025-11-16 16:47:49+00:00   train_model         1.000443   \n",
       "1 2025-11-16 16:47:49+00:00   train_model         1.000705   \n",
       "2 2025-11-16 16:47:49+00:00   train_model         1.000741   \n",
       "3 2025-11-16 16:47:49+00:00   train_model         1.001190   \n",
       "4 2025-11-16 16:47:49+00:00   train_model         1.000646   \n",
       "\n",
       "                                         params              metrics  \n",
       "0  {'learning_rate': 0.05, 'n_estimators': 200}  {'f1_score': 0.785}  \n",
       "1  {'learning_rate': 0.01, 'n_estimators': 500}  {'f1_score': 0.751}  \n",
       "2  {'learning_rate': 0.01, 'n_estimators': 300}  {'f1_score': 0.771}  \n",
       "3   {'learning_rate': 0.1, 'n_estimators': 200}   {'f1_score': 0.79}  \n",
       "4  {'learning_rate': 0.05, 'n_estimators': 100}  {'f1_score': 0.795}  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Find all log files that match the pattern\n",
    "log_files = glob.glob(f\"{LOG_FILE}.*\")\n",
    "\n",
    "# 2. Read them all into a list of DataFrames\n",
    "df_list = [pd.read_json(f, lines=True) for f in log_files]\n",
    "\n",
    "# 3. Combine them into one master DataFrame!\n",
    "df_raw = pd.concat(df_list, ignore_index=True)\n",
    "\n",
    "print(f\"Combined {len(log_files)} log files into a single DataFrame with {len(df_raw)} runs.\")\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2a2c7c",
   "metadata": {},
   "source": [
    "### 7. Flatten and Find the Best Model\n",
    "\n",
    "Now that we have our combined `df_raw`, we can analyze it just like we did in the simple demo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d8c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the 'params' and 'metrics' columns\n",
    "df_params = pd.json_normalize(df_raw['params']).add_prefix('param_')\n",
    "df_metrics = pd.json_normalize(df_raw['metrics']).add_prefix('metric_')\n",
    "\n",
    "# Join them all together\n",
    "df_analysis = pd.concat([\n",
    "    df_raw.drop(['params', 'metrics'], axis=1), \n",
    "    df_params, \n",
    "    df_metrics\n",
    "], axis=1)\n",
    "\n",
    "# Sort by F1 score to find the best run!\n",
    "df_sorted = df_analysis.sort_values(by=\"metric_f1_score\", ascending=False)\n",
    "\n",
    "df_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tinylogger-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
